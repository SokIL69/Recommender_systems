{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Рекомендательные системы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Урок 5. Поиск похожих товаров и пользователей. Гибридные рекомендательные системы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Прочитать статьи про BPR, WARP loss\n",
    "\n",
    "2) Сделать грид серч текущей модели, смотрите на метрику precision@5, считаем на тесте нашей функцией"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполнил Соковнин ИЛ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install lightfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'implicit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-2f918af4e8de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Матричная факторизация\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mimplicit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mals\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAlternatingLeastSquares\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mimplicit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnearest_neighbours\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbm25_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtfidf_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'implicit'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Для работы с матрицами\n",
    "from scipy.sparse import csr_matrix, coo_matrix\n",
    "\n",
    "# Матричная факторизация\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from implicit.nearest_neighbours import bm25_weight, tfidf_weight\n",
    "\n",
    "from lightfm import LightFM\n",
    "\n",
    "# Функции из 1-ого вебинара\n",
    "import os, sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(os.pardir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm.evaluation import precision_at_k, recall_at_k\n",
    "\n",
    "from metrics import precision_at_k as custom_precision, recall_at_k\n",
    "from utils import prefilter_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/retail_train.csv')\n",
    "\n",
    "item_features = pd.read_csv('../data/product.csv')\n",
    "user_features = pd.read_csv('../data/hh_demographic.csv')\n",
    "\n",
    "# column processing\n",
    "item_features.columns = [col.lower() for col in item_features.columns]\n",
    "user_features.columns = [col.lower() for col in user_features.columns]\n",
    "\n",
    "item_features.rename(columns={'product_id': 'item_id'}, inplace=True)\n",
    "user_features.rename(columns={'household_key': 'user_id'}, inplace=True)\n",
    "\n",
    "# train test split\n",
    "test_size_weeks = 3  # 3 weeks\n",
    "\n",
    "data_train = data[data['week_no'] < data['week_no'].max() - test_size_weeks]\n",
    "data_test = data[data['week_no'] >= data['week_no'].max() - test_size_weeks]\n",
    "\n",
    "data_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls ../data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = data_test.groupby('user_id')['item_id'].unique().reset_index()\n",
    "result.columns=['user_id', 'actual']\n",
    "result.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_features.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features['age_desc'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features['marital_status_code'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features['household_size_desc'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Filter items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Фильтрация товара. Оставляем 5000 самых популярных товаров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_items_before = data_train['item_id'].nunique()\n",
    "\n",
    "data_train_filtered = prefilter_items(data_train, take_n_popular=5000, item_features=item_features)\n",
    "\n",
    "n_items_after = data_train_filtered['item_id'].nunique()\n",
    "print('Decreased # items from {} to {}'.format(n_items_before, n_items_after))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Prepare data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Prepare csr train matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "user_item_matrix = pd.pivot_table(data_train_filtered, \n",
    "                                  index='user_id', columns='item_id', \n",
    "                                  values='quantity', # Можно пробоват ьдругие варианты\n",
    "                                  aggfunc='count', \n",
    "                                  fill_value=0\n",
    "                                 )\n",
    "\n",
    "user_item_matrix = user_item_matrix.astype(float) # необходимый тип матрицы для implicit\n",
    "\n",
    "# переведем в формат sparse matrix\n",
    "sparse_user_item = csr_matrix(user_item_matrix).tocsr()\n",
    "\n",
    "user_item_matrix.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Prepare CSR test matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data_test[data_test['item_id'].isin(data_train['item_id'].unique())]\n",
    "\n",
    "test_user_item_matrix = pd.pivot_table(data_test, \n",
    "                                  index='user_id', columns='item_id', \n",
    "                                  values='quantity', # Можно пробоват ьдругие варианты\n",
    "                                  aggfunc='count', \n",
    "                                  fill_value=0\n",
    "                                 )\n",
    "\n",
    "test_user_item_matrix = test_user_item_matrix.astype(float) # необходимый тип матрицы для implicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user_item_matrix.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userids = user_item_matrix.index.values\n",
    "itemids = user_item_matrix.columns.values\n",
    "\n",
    "matrix_userids = np.arange(len(userids))\n",
    "matrix_itemids = np.arange(len(itemids))\n",
    "\n",
    "# Cтроим матрицу преобразования\n",
    "id_to_itemid = dict(zip(matrix_itemids, itemids))\n",
    "id_to_userid = dict(zip(matrix_userids, userids))\n",
    "\n",
    "itemid_to_id = dict(zip(itemids, matrix_itemids))\n",
    "userid_to_id = dict(zip(userids, matrix_userids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare user and item features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_feat = pd.DataFrame(user_item_matrix.index)\n",
    "user_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объединение — функция pandas. merge() соединяет строки в Dataframe на основе одного или нескольких ключей.\n",
    "user_feat = user_feat.merge(user_features, on='user_id', how='left')\n",
    "user_feat.set_index('user_id', inplace=True)\n",
    "user_feat.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_feat = pd.DataFrame(user_item_matrix.columns)\n",
    "item_feat = item_feat.merge(item_features, on='item_id', how='left')\n",
    "item_feat.set_index('item_id', inplace=True)\n",
    "\n",
    "item_feat.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_feat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кодирование в бинарном виде\n",
    "user_feat_lightfm = pd.get_dummies(user_feat, columns=user_feat.columns.tolist())\n",
    "item_feat_lightfm = pd.get_dummies(item_feat, columns=item_feat.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_feat_lightfm.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LightFM(no_components=40,\n",
    "                loss='bpr', # \"logistic\",\"bpr\"\n",
    "                learning_rate=0.01, \n",
    "                item_alpha=0.4,\n",
    "                user_alpha=0.1, \n",
    "                random_state=42,\n",
    "                k=5,\n",
    "                n=15,\n",
    "                max_sampled=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit((sparse_user_item > 0) * 1,  # user-item matrix из 0 и 1\n",
    "          sample_weight=coo_matrix(user_item_matrix),\n",
    "          user_features=csr_matrix(user_feat_lightfm.values).tocsr(),\n",
    "          item_features=csr_matrix(item_feat_lightfm.values).tocsr(),\n",
    "          epochs=20, \n",
    "          num_threads=20,\n",
    "          verbose=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting embeddings\n",
    "Векторизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## вектора по пользователям"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_emb = model.get_user_representations(features=csr_matrix(user_feat_lightfm.values).tocsr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_emb[0].shape # biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_emb[1].shape # users vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## вектора по товарам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_emb = model.get_item_representations(features=csr_matrix(item_feat_lightfm.values).tocsr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_emb[0].shape # biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_emb[1].shape # items vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation -> Train precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценка -> Тренировка точности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# мы можем использовать встроенные метрики lightFM\n",
    "train_precision = precision_at_k(model, sparse_user_item, \n",
    "                                 user_features=csr_matrix(user_feat_lightfm.values).tocsr(),\n",
    "                                 item_features=csr_matrix(item_feat_lightfm.values).tocsr(),\n",
    "                                 k=5).mean()\n",
    "\n",
    "print(f\"Train precision {train_precision}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# подготавливаемм id для юзеров и товаров в порядке пар user-item\n",
    "users_ids_row = data_train_filtered['user_id'].apply(lambda x: userid_to_id[x]).values.astype(int)\n",
    "items_ids_row = data_train_filtered['item_id'].apply(lambda x: itemid_to_id[x]).values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_ids_row[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_ids_row[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# модель возвращает меру/скор похожести между соответствующим пользователем и товаром\n",
    "predictions = model.predict(user_ids=users_ids_row,\n",
    "                            item_ids=items_ids_row,\n",
    "                            user_features=csr_matrix(user_feat_lightfm.values).tocsr(),\n",
    "                            item_features=csr_matrix(item_feat_lightfm.values).tocsr(),\n",
    "                            num_threads=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавляем наш полученный скор в трейн датафрейм\n",
    "data_train_filtered['score'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем предикт датафрейм в формате списка товаров\n",
    "predict_result = data_train_filtered[['user_id','item_id','score']][data_train_filtered.item_id != 999999].drop_duplicates().sort_values(by=['user_id','score'], ascending=False).groupby('user_id')['item_id']. \\\n",
    "            unique().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# объединяем предикт и тест датасет для подсчета precision\n",
    "df_result_for_metrics = result.merge(predict_result, on='user_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_for_metrics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with custom precision func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = df_result_for_metrics.apply(lambda row: custom_precision(row['item_id'], row['actual'],k=5), axis=1).mean()\n",
    "print(f\"Precision: {precision}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks for RS: http://d2l.ai/chapter_recommender-systems/mf.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LigthFM -> https://arxiv.org/pdf/1507.08439.pdf\n",
    "\n",
    "https://making.lyst.com/lightfm/docs/home.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Прочитать статьи про BPR, WARP loss\n",
    "2. Сделать грид серч текущей модели, смотрите на метрику precision@5, считаем на тесте нашей функцией"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='color:blue'>Ищем оптимальные параметры (grid-search)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicts(users_ids_row, items_ids_row):\n",
    "       \n",
    "    # модель возвращает меру/скор похожести между соответствующим пользователем и товаром\n",
    "    predictions = model.predict(user_ids=users_ids_row,\n",
    "                                item_ids=items_ids_row,\n",
    "                                user_features=csr_matrix(user_feat_lightfm.values).tocsr(),\n",
    "                                item_features=csr_matrix(item_feat_lightfm.values).tocsr(),\n",
    "                                num_threads=10)\n",
    "    # добавляем наш полученный скор в трейн датафрейм\n",
    "    data_train_filtered['score'] = predictions\n",
    "    # создаем предикт датафрейм в формате списка товаров\n",
    "    predict_result = data_train_filtered[['user_id','item_id','score']][data_train_filtered.item_id != 999999]. \\\n",
    "            drop_duplicates().sort_values(by=['user_id','score'], ascending=False).groupby('user_id')['item_id']. \\\n",
    "            unique().reset_index()\n",
    "    \n",
    "    # объединяем предикт и тест датасет для подсчета precision\n",
    "    # df_result_for_metrics \n",
    "    res = result.merge(predict_result, on='user_id', how='inner')\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_curve(model, user_item_matrix, epochs, num_threads):\n",
    "    user_item_precision = []\n",
    "    \n",
    "#     headers = ['epochs', 'p@k user_item_matrix']\n",
    "\n",
    "    \n",
    "    model.fit((sparse_user_item > 0) * 1,  # user-item matrix из 0 и 1\n",
    "      sample_weight=coo_matrix(user_item_matrix),\n",
    "      user_features=csr_matrix(user_feat_lightfm.values).tocsr(),\n",
    "      item_features=csr_matrix(item_feat_lightfm.values).tocsr(),\n",
    "      # epochs=20, \n",
    "      # num_threads=20,\n",
    "      verbose=True) \n",
    "\n",
    "    # подготавливаемм id для юзеров и товаров в порядке пар user-item\n",
    "    users_ids_row = data_train_filtered['user_id'].apply(lambda x: userid_to_id[x]).values.astype(int)\n",
    "    items_ids_row = data_train_filtered['item_id'].apply(lambda x: itemid_to_id[x]).values.astype(int)\n",
    "    \n",
    "    df_result_for_metrics = get_predicts(users_ids_row, items_ids_row)\n",
    "    precision = df_result_for_metrics.apply(lambda row: custom_precision(row['item_id'], \\\n",
    "                                                                         row['actual'],k=5), axis=1).mean()\n",
    "    user_item_precision.append(precision)\n",
    "\n",
    "    return model, user_item_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_learning_curve(base_model, user_item_matrix, param_grid,\n",
    "                               user_index=None, patk=5, epochs=range(2, 40, 2)):\n",
    "    \"\"\"\n",
    "    \"Inspired\" (stolen) from sklearn gridsearch\n",
    "    https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/model_selection/_search.py\n",
    "    \"\"\"\n",
    "    curves = []\n",
    "    keys, values = zip(*param_grid.items())\n",
    "    for v in itertools.product(*values):\n",
    "        params = dict(zip(keys, v))\n",
    "        this_model = copy.deepcopy(base_model)\n",
    "        print_line = []\n",
    "        for k, v in params.items():\n",
    "            setattr(this_model, k, v)\n",
    "            print_line.append((k, v))\n",
    "\n",
    "        print(' | '.join('{}: {}'.format(k, v) for (k, v) in print_line))\n",
    "        \n",
    "        _, user_item_patk = learning_curve(this_model, user_item_matrix)\n",
    "        \n",
    "        curves.append({'params': params,\n",
    "                       'patk': {'user_item_matrix': user_item_patk}})\n",
    "    return curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'no_components': [20, 40],\n",
    "              'learning_rate': [0.01],\n",
    "              'item_alpha': [0.4],\n",
    "              'user_alpha': [0.1],              \n",
    "              'k': [3, 5],\n",
    "              'max_sampled': [50, 100],\n",
    "             }\n",
    "\n",
    "user_index = range(user_item_matrix.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = LightFM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curves = grid_search_learning_curve(base_model, user_item_matrix,\n",
    "                                    param_grid,\n",
    "                                    user_index=user_index,\n",
    "                                    patk=5)\n",
    "\n",
    "user_index = range(user_item_matrix.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(curves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curves[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
